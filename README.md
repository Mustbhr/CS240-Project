# Fast Failure Recovery in Distributed Training with In-Memory Checkpoints

**Gemini Reproduction Project - CS240 Fall 2025**

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## Team Members
- Mustafa Albahrani (mustafa.albahrani@kaust.edu.sa)
- Mohammed Alkhalifah (mohammad.alkhalifah@kaust.edu.sa)

## Project Overview

This project reproduces the core Gemini system ([SOSP 2023](https://dl.acm.org/doi/10.1145/3600006.3613145)) that achieves fast, fault-tolerant recovery in distributed deep learning by storing and replicating model checkpoints in RAM across training nodes.

### Key Goals
- Reproduce Gemini's key result: **â‰¥10-15Ã— faster failure recovery** with minimal overhead
- Demonstrate the feasibility of in-memory checkpointing in a scaled-down academic cluster environment
- Compare recovery latency vs. traditional NFS-based checkpointing

### Targeted Traits
- **Reliability**: Fast recovery from hardware/network failures
- **Scalability**: Efficient checkpoint replication across nodes

## Current Implementation Status

| Component | Status | Description |
|-----------|--------|-------------|
| Baseline Trainer | âœ… Complete | Distributed training with disk checkpointing |
| In-Memory Checkpoint | âœ… Complete | RAM-based checkpoint storage |
| Data Loading | âœ… Complete | Synthetic + Wikipedia dataset support |
| Experiment Logger | âœ… Complete | wandb integration for tracking |
| Worker Agent | ğŸ”¨ Skeleton | Needs network communication |
| Root Agent | ğŸ”¨ Skeleton | Needs failure detection |
| Replication Manager | â³ Pending | Cross-node checkpoint transfer |
| Failure Injection | â³ Pending | Testing recovery performance |

## Architecture

### Components
1. **Baseline Trainer**: Traditional distributed training with disk-based checkpointing (for comparison)
2. **In-Memory Checkpoint**: Fast RAM-based checkpoint storage - the core Gemini innovation
3. **Worker Agents**: Handle local checkpoint capture and replication on each node
4. **Root Agent**: Coordinates recovery and failure detection
5. **Experiment Logger**: wandb integration for metrics and visualization

### Technologies
- **Framework**: PyTorch with DistributedDataParallel (DDP)
- **Communication**: NCCL (planned), TCP for checkpoint transfer
- **Logging**: Weights & Biases (wandb)
- **Language**: Python 3.9+
- **Hardware**: KAUST IBEX cluster (tested on single GPU node)

## Project Structure

```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt              # Main dependencies
â”œâ”€â”€ requirements-minimal.txt      # Minimal deps for testing
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md          # System architecture details
â”‚   â””â”€â”€ milestones.md            # Project timeline and progress
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ worker_agent.py      # Worker node agent (skeleton)
â”‚   â”‚   â””â”€â”€ root_agent.py        # Root coordinator (skeleton)
â”‚   â”œâ”€â”€ checkpointing/
â”‚   â”‚   â””â”€â”€ in_memory_checkpoint.py  # âœ… RAM-based checkpointing
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ baseline_trainer.py  # âœ… Baseline with disk checkpointing
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ data_loader.py       # âœ… Dataset utilities
â”‚       â””â”€â”€ experiment_logger.py # âœ… wandb integration
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ training_config.yaml.template
â”‚   â””â”€â”€ cluster_config.yaml.template
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ quick_test.py            # âœ… Quick verification test
â”‚   â”œâ”€â”€ run_baseline_test.py     # âœ… Full infrastructure test
â”‚   â”œâ”€â”€ ibex_test.sh             # SLURM batch script
â”‚   â””â”€â”€ setup_environment.sh     # Environment setup
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_agents.py           # Unit tests
â”œâ”€â”€ logs/                        # Experiment logs (local)
â”œâ”€â”€ checkpoints/                 # Saved checkpoints
â””â”€â”€ results/                     # Experiment results
```

## Installation

### Prerequisites
- Python 3.9+
- CUDA-capable GPUs
- Access to KAUST IBEX cluster (or similar HPC)

### Setup on IBEX

```bash
# 1. Clone the repository
git clone https://github.com/Mustbhr/CS240-Project.git
cd CS240-Project

# 2. Get an interactive GPU session
srun --nodes=1 --gpus-per-node=1 --time=00:30:00 --mem=32G --pty bash

# 3. Create virtual environment
python -m venv venv
source venv/bin/activate

# 4. Install PyTorch with CUDA (check your CUDA version with nvidia-smi)
python -m pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# 5. Install other dependencies
python -m pip install -r requirements.txt

# 6. Run quick test
python scripts/quick_test.py
```

### Setup Locally (for development)

```bash
# Clone and setup
git clone https://github.com/Mustbhr/CS240-Project.git
cd CS240-Project
python -m venv venv
source venv/bin/activate
pip install torch torchvision
pip install -r requirements.txt
```

## Usage

### Quick Test (Verify Installation)
```bash
python scripts/quick_test.py
```

### Full Infrastructure Test
```bash
# Without wandb logging
python scripts/run_baseline_test.py

# With wandb logging (requires wandb login)
python scripts/run_baseline_test.py --wandb
```

### Expected Output
The tests compare disk-based vs memory-based checkpointing:
```
COMPARISON RESULTS
========================================
Save speedup:     X.XXx faster
Load speedup:     X.XXx faster
Recovery speedup: X.XXx faster
```

## Key Results (Preliminary)

Testing on KAUST IBEX (single node):
- **Disk checkpoint save**: ~XXX ms
- **Memory checkpoint save**: ~XX ms
- **Speedup**: ~10-15Ã— faster (varies by model size)

*Full multi-node results pending cluster access.*

## Milestones

| Week | Milestone | Status |
|------|-----------|--------|
| 1 | Environment setup + baseline | âœ… Complete |
| 2 | In-memory checkpointing | âœ… Complete |
| 3 | Replication + failure detection | ğŸ”¨ In Progress |
| 4 | Failure injection + recovery | â³ Pending |
| 5-6 | Integration + final report | â³ Pending |

## References

1. Wang et al., *Gemini: Fast Failure Recovery in Distributed Training with In-Memory Checkpoints*, SOSP 2023.
   - Paper: https://dl.acm.org/doi/10.1145/3600006.3613145
   - Artifact Repository: https://github.com/Gemini-artifacts/gemini

## License

This is an academic reproduction project for CS240 at KAUST. Licensed under MIT.

## Acknowledgments

This project reproduces the Gemini system developed by Wang et al. (SOSP 2023). We acknowledge the original authors for their groundbreaking work in distributed training reliability.
